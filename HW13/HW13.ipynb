{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_HW13.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Tf-jnHngag-m",
        "h_dp3WT7FW8E",
        "259V3MeC9G55",
        "h7UbcqmKUZ1q",
        "IABul8FSEiB-",
        "p6Up_S1ekykr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "05e4mKftC8BP"
      },
      "source": [
        "#@title Student Information\n",
        "#@markdown Enter the following info and run the cell:\n",
        "Name = \"Arman Heydari\" #@param {type:\"string\"}\n",
        "StudentNumber =  97521252#@param {type:\"integer\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf-jnHngag-m"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJBzDr12K3bf"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0twGcAkFWiG"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import IPython\n",
        "from IPython.display import clear_output \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "%matplotlib inline"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGw9iBLGU9Cu",
        "outputId": "2feb8bd1-30cb-4aa6-e576-d6797e74aaa3"
      },
      "source": [
        "!nvidia-smi # check if gpu mode is selected"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JqUZuEo8G_p"
      },
      "source": [
        "We will use a dataset consists of questions where a previously given single supporting fact, potentially amongst a set of other irrelevant facts, provides the answer. We first test one of the simplest cases of this, by asking for the location of a person, e.g. “$Mary$ $travelled$ $to$ $the$ $office.$ $Where$ $is$ $Mary?$”. It can be considered the\n",
        "simplest case of some real world QA datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsvVnfvfGnib"
      },
      "source": [
        "About the dataset: https://research.fb.com/downloads/babi/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OlahJ1OrKjd"
      },
      "source": [
        "Lets download the dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_dp3WT7FW8E"
      },
      "source": [
        "# 1. LSTM- Q&A\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "259V3MeC9G55"
      },
      "source": [
        "## 1.2 Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u_xDAfovXf7"
      },
      "source": [
        "Our model takes a discrete set of inputs $x_{1}, ..., x_{n}$ that are to be stored in the memory, a query $q$, and outputs an answer $a$. Each of the $x_{i}$, $q$, and $a$ contains symbols coming from a dictionary with $V$ words. The model writes all $x$ to the memory up to a fixed buffer size, and then finds a continuous representation for the $x$ and $q$. The continuous representation is then processed via multiple hops to\n",
        "output $a$. This allows backpropagation of the error signal through multiple memory accesses back to the input during training. The overall model is shown in the next figure. During training, all three embedding matrices $A, B$ and $C$, as well as $W$ are jointly learned by minimizing a standard cross-entropy loss between $aˆ$ and the true\n",
        "label $a$. Training is performed using stochastic gradient descent.\n",
        "\n",
        "\n",
        "Delve more deeply into the details: https://arxiv.org/pdf/1503.08895.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx-wpcdQJfpk"
      },
      "source": [
        "%%capture\n",
        "!wget https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
        "!tar -xvzf babi_tasks_1-20_v1-2.tar.gz"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBYgDigJanwz"
      },
      "source": [
        "challenges = [\n",
        "    'qa1_single-supporting-fact',\n",
        "    'qa2_two-supporting-facts',\n",
        "]\n",
        "train_file_path = f'/content/tasks_1-20_v1-2/en-10k/{challenges[0]}_train.txt'\n",
        "test_file_path = f'/content/tasks_1-20_v1-2/en-10k/{challenges[0]}_test.txt'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCBfH4qrrKjL"
      },
      "source": [
        "def word_tokenizer(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)', sent) if x.strip()]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WLJmevS-Dy6"
      },
      "source": [
        "According to the dataset (bAbi tasks), we need to prepare the data for training the model. With the next function we parse the dataset and manufactore it in desired way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzksSX8drKjP"
      },
      "source": [
        "def parse_stories(lines, only_supporting=False, tokenize = True):\n",
        "    '''Parse stories provided in the bAbi tasks format\n",
        "    If only_supporting is true, only the sentences\n",
        "    that support the answer are kept.\n",
        "    '''\n",
        "    data = []\n",
        "    story = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        nid, line = line.split(' ', 1)\n",
        "        nid = int(nid)\n",
        "        if nid == 1:\n",
        "            story = []\n",
        "        if '\\t' in line:\n",
        "            q, a, supporting = line.split('\\t')\n",
        "            if tokenize:\n",
        "                q = word_tokenizer(q)\n",
        "            substory = None\n",
        "            if only_supporting:\n",
        "                # Only select the related substory\n",
        "                supporting = map(int, supporting.split())\n",
        "                substory = [story[i - 1] for i in supporting]\n",
        "            else:\n",
        "                # Provide all the substories\n",
        "                substory = [x for x in story if x]\n",
        "            data.append((substory, q, a))\n",
        "            story.append('')\n",
        "        else:\n",
        "            if tokenize:\n",
        "                sent = word_tokenizer(line)\n",
        "            else:\n",
        "                sent = line\n",
        "            story.append(sent)\n",
        "    return data\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwkiTJYRJvPe"
      },
      "source": [
        "Now we need to take proper structure of the data: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBc_rzF-rKjT"
      },
      "source": [
        "def get_stories(f, only_supporting=False, max_length=None, tokenize=True):\n",
        "    data = parse_stories(f.readlines(), only_supporting=only_supporting, tokenize=tokenize)\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "    data = [(story[0]+story[1], q, answer) for story, q, answer in data if not max_length or len(flatten(story)) < max_length]\n",
        "    return data"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FivvTCc8J-GW"
      },
      "source": [
        "Here we need to make the vectors of stories, questions and answers. its too easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzEnmDN_rKjW"
      },
      "source": [
        "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
        "  \n",
        "  inputs_train = np.zeros((len(data), story_maxlen))\n",
        "  queries_train = np.zeros((len(data), query_maxlen))\n",
        "  answers_train = np.zeros((len(data), len(word_idx)+1))\n",
        "\n",
        "  i = 0\n",
        "  for informations, question, answer in data:\n",
        "    j = 0\n",
        "    for word in informations:\n",
        "      inputs_train[i, j] = word_idx[word]\n",
        "      j+=1\n",
        "\n",
        "    j = 0\n",
        "    for word in question:\n",
        "      queries_train[i, j] = word_idx[word]\n",
        "      j+=1\n",
        "\n",
        "    answers_train[i, word_idx[answer]] = 1\n",
        "    \n",
        "    i+=1\n",
        "  return inputs_train, queries_train, answers_train\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B77myra2ZJYK"
      },
      "source": [
        "Its time to extract stories from the dataset, then pass them to the defined functions for parsing and make it usable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akcwoo3frKjj"
      },
      "source": [
        "train_stories = get_stories(open(train_file_path), tokenize=True)\n",
        "test_stories = get_stories(open(test_file_path), tokenize=True)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyiMaVRirKjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457de7c9-d6ca-4801-a393-026f275dc004"
      },
      "source": [
        "len(train_stories), len(test_stories)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpXH9iYQrKjq"
      },
      "source": [
        "## 1.3 Check our helper functions and prepare the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29110FTDrKjr"
      },
      "source": [
        "vocab = set()\n",
        "for story, q, answer in train_stories + test_stories:\n",
        "    vocab |= set(story + q + [answer])\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "# Reserve 0 for masking via pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
        "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PopB46hnrKju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb5f50b-2d9c-4693-ce91-8d06f6ead08a"
      },
      "source": [
        "story_maxlen, query_maxlen, vocab_size"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 4, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-G22KfxrKjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bd5623-5021-42fc-8353-c9268b7a5757"
      },
      "source": [
        "print('-')\n",
        "print('Vocab size:', vocab_size, 'unique words')\n",
        "print('Story max length:', story_maxlen, 'words')\n",
        "print('Query max length:', query_maxlen, 'words')\n",
        "print('Number of training stories:', len(train_stories))\n",
        "print('Number of test stories:', len(test_stories))\n",
        "print('-')\n",
        "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
        "print(train_stories[0])\n",
        "print('-')\n",
        "print('Vectorizing the word sequences...')\n",
        "\n",
        "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
        "idx_word = dict((i+1, c) for i,c in enumerate(vocab))\n",
        "inputs_train, queries_train, answers_train = vectorize_stories(train_stories,\n",
        "                                                               word_idx,\n",
        "                                                               story_maxlen,\n",
        "                                                               query_maxlen)\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_stories,\n",
        "                                                            word_idx,\n",
        "                                                            story_maxlen,\n",
        "                                                            query_maxlen)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Vocab size: 22 unique words\n",
            "Story max length: 14 words\n",
            "Query max length: 4 words\n",
            "Number of training stories: 10000\n",
            "Number of test stories: 1000\n",
            "-\n",
            "Here's what a \"story\" tuple looks like (input, query, answer):\n",
            "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'John', 'went', 'to', 'the', 'hallway', '.'], ['Where', 'is', 'Mary', '?'], 'bathroom')\n",
            "-\n",
            "Vectorizing the word sequences...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMnIXlTBrKj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b317a8-a84b-402c-9dc2-272852b47cec"
      },
      "source": [
        "inputs_train.shape, queries_train.shape, answers_train.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 14), (10000, 4), (10000, 22))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4lNOEBkrKj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d497e3-42f1-4b9f-d489-2f9277a0c026"
      },
      "source": [
        "print('-')\n",
        "print('inputs: integer tensor of shape (samples, max_length)')\n",
        "print('inputs_train shape:', inputs_train.shape)\n",
        "print('inputs_test shape:', inputs_test.shape)\n",
        "print('-')\n",
        "print('queries: integer tensor of shape (samples, max_length)')\n",
        "print('queries_train shape:', queries_train.shape)\n",
        "print('queries_test shape:', queries_test.shape)\n",
        "print('-')\n",
        "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
        "print('answers_train shape:', answers_train.shape)\n",
        "print('answers_test shape:', answers_test.shape)\n",
        "print('-')\n",
        "print('Compiling...')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "inputs: integer tensor of shape (samples, max_length)\n",
            "inputs_train shape: (10000, 14)\n",
            "inputs_test shape: (1000, 14)\n",
            "-\n",
            "queries: integer tensor of shape (samples, max_length)\n",
            "queries_train shape: (10000, 4)\n",
            "queries_test shape: (1000, 4)\n",
            "-\n",
            "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
            "answers_train shape: (10000, 22)\n",
            "answers_test shape: (1000, 22)\n",
            "-\n",
            "Compiling...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvyawLqgfz_N"
      },
      "source": [
        "In this part you should implement 2 functions which illustrate the procedure of learning, Loss and Accuracy. These functions take two inputs: \n",
        "* The history of your designed model \n",
        "* Proper title for describing the plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8Ya5e3e3OWG"
      },
      "source": [
        "def plot_acc(history, title):\n",
        "  print(\"maximum accuracy is\", np.max(history.history['accuracy']), \"on epoch\", np.argmax(history.history['accuracy'])+1)\n",
        "  print()\n",
        "  plt.plot(history.history['accuracy'],label=\"train accuracy\")\n",
        "  plt.plot(history.history['val_accuracy'],label=\"validation accuracy\")\n",
        "  \n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(title)\n",
        "  \n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA9BBcEP3Hym"
      },
      "source": [
        "def plot_loss(history, title):\n",
        "  print(\"minimum loss is\", np.min(history.history['loss']), \"on epoch\", np.argmin(history.history['loss'])+1)\n",
        "  print()\n",
        "  plt.plot(history.history['loss'],label=\"train loss\")\n",
        "  plt.plot(history.history['val_loss'],label=\"validation loss\")\n",
        "  \n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(title)\n",
        "  \n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMxMeM78xBT8"
      },
      "source": [
        "Define model's hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6-mw90LrKj9"
      },
      "source": [
        "train_epochs = 10\n",
        "batch_size = 32\n",
        "lstm_size = 64"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G5X8ksgrKkA"
      },
      "source": [
        "## 1.4 Implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayB5NMoI-Sh-"
      },
      "source": [
        "Let's build the model. You should use Keras framework. The summary and outview of the right model is saved in the next cells to help you create the proper model faster.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UNREQ9rrKkB"
      },
      "source": [
        "# defne the model: \n",
        "input_sequence = tf.keras.layers.Input((story_maxlen,))\n",
        "question = tf.keras.layers.Input((query_maxlen,))\n",
        "\n",
        "sequential1 = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, 64)])(input_sequence)\n",
        "sequential2 = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, 4)])(input_sequence)\n",
        "\n",
        "sequential3 = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, 64)])(question)\n",
        "\n",
        "dot = tf.keras.layers.Dot(axes=(2, 2))([sequential1, sequential3])\n",
        "activation = tf.keras.layers.Activation('relu')(dot)\n",
        "\n",
        "add = tf.keras.layers.Add()([activation, sequential2])\n",
        "\n",
        "permute = tf.keras.layers.Permute((2, 1))(add)\n",
        "\n",
        "concat = tf.keras.layers.Concatenate()([permute, sequential3])\n",
        "\n",
        "lstm = tf.keras.layers.LSTM(lstm_size)(concat)\n",
        "\n",
        "dropout = tf.keras.layers.Dropout(0.1)(lstm)\n",
        "\n",
        "dense = tf.keras.layers.Dense(vocab_size)(dropout)\n",
        "\n",
        "output = tf.keras.layers.Activation('softmax')(dense)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUvfDiLkrKkF"
      },
      "source": [
        "# build the final model\n",
        "model = tf.keras.models.Model([input_sequence, question], output)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFqPorzN_9Lv"
      },
      "source": [
        "The model architecture should look like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX6c1qWQ0iMX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61b52e9a-badd-445e-e725-1d43181c00ce"
      },
      "source": [
        "from IPython.display import SVG\n",
        "\n",
        "SVG(tf.keras.utils.model_to_dot(model,show_shapes= True, show_layer_names=True, dpi=60).create(prog='dot', format='svg'))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"737pt\" viewBox=\"0.00 0.00 898.00 885.00\" width=\"748pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.8333 .8333) rotate(0) translate(4 881)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-881 894,-881 894,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140485076724240 -->\n<g class=\"node\" id=\"node1\">\n<title>140485076724240</title>\n<polygon fill=\"none\" points=\"114,-830.5 114,-876.5 403,-876.5 403,-830.5 114,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"145\" y=\"-849.8\">input_3</text>\n<polyline fill=\"none\" points=\"176,-830.5 176,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216\" y=\"-849.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"256,-830.5 256,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"256,-853.5 314,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"314,-830.5 314,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"358.5\" y=\"-861.3\">[(None, 14)]</text>\n<polyline fill=\"none\" points=\"314,-853.5 403,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"358.5\" y=\"-838.3\">[(None, 14)]</text>\n</g>\n<!-- 140485076682832 -->\n<g class=\"node\" id=\"node3\">\n<title>140485076682832</title>\n<polygon fill=\"none\" points=\"186,-747.5 186,-793.5 529,-793.5 529,-747.5 186,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.5\" y=\"-766.8\">sequential_2</text>\n<polyline fill=\"none\" points=\"275,-747.5 275,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-766.8\">Sequential</text>\n<polyline fill=\"none\" points=\"352,-747.5 352,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"381\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"352,-770.5 410,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"381\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"410,-747.5 410,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469.5\" y=\"-778.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"410,-770.5 529,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"469.5\" y=\"-755.3\">(None, None, 64)</text>\n</g>\n<!-- 140485076724240&#45;&gt;140485076682832 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140485076724240-&gt;140485076682832</title>\n<path d=\"M286.077,-830.3799C297.1407,-821.1043 310.0354,-810.2936 321.7999,-800.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"324.313,-802.8908 329.7275,-793.784 319.8157,-797.5266 324.313,-802.8908\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076743568 -->\n<g class=\"node\" id=\"node7\">\n<title>140485076743568</title>\n<polygon fill=\"none\" points=\"0,-664.5 0,-710.5 335,-710.5 335,-664.5 0,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"44.5\" y=\"-683.8\">sequential_3</text>\n<polyline fill=\"none\" points=\"89,-664.5 89,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127.5\" y=\"-683.8\">Sequential</text>\n<polyline fill=\"none\" points=\"166,-664.5 166,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"166,-687.5 224,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"224,-664.5 224,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-695.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"224,-687.5 335,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-672.3\">(None, None, 4)</text>\n</g>\n<!-- 140485076724240&#45;&gt;140485076743568 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140485076724240-&gt;140485076743568</title>\n<path d=\"M212.5992,-830.3499C198.6872,-821.0004 184.884,-808.8593 176.5,-794 164.0409,-771.9181 162.3179,-743.0677 163.4197,-720.9653\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"166.9303,-720.9405 164.1528,-710.7163 159.9481,-720.441 166.9303,-720.9405\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076690064 -->\n<g class=\"node\" id=\"node2\">\n<title>140485076690064</title>\n<polygon fill=\"none\" points=\"578,-830.5 578,-876.5 859,-876.5 859,-830.5 578,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609\" y=\"-849.8\">input_4</text>\n<polyline fill=\"none\" points=\"640,-830.5 640,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"680\" y=\"-849.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"720,-830.5 720,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"749\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"720,-853.5 778,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"749\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"778,-830.5 778,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"818.5\" y=\"-861.3\">[(None, 4)]</text>\n<polyline fill=\"none\" points=\"778,-853.5 859,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"818.5\" y=\"-838.3\">[(None, 4)]</text>\n</g>\n<!-- 140485076760208 -->\n<g class=\"node\" id=\"node4\">\n<title>140485076760208</title>\n<polygon fill=\"none\" points=\"547,-747.5 547,-793.5 890,-793.5 890,-747.5 547,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"591.5\" y=\"-766.8\">sequential_4</text>\n<polyline fill=\"none\" points=\"636,-747.5 636,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674.5\" y=\"-766.8\">Sequential</text>\n<polyline fill=\"none\" points=\"713,-747.5 713,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"742\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"713,-770.5 771,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"742\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"771,-747.5 771,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"830.5\" y=\"-778.3\">(None, None)</text>\n<polyline fill=\"none\" points=\"771,-770.5 890,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"830.5\" y=\"-755.3\">(None, None, 64)</text>\n</g>\n<!-- 140485076690064&#45;&gt;140485076760208 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140485076690064-&gt;140485076760208</title>\n<path d=\"M718.5,-830.3799C718.5,-822.1745 718.5,-812.7679 718.5,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"722.0001,-803.784 718.5,-793.784 715.0001,-803.784 722.0001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076743440 -->\n<g class=\"node\" id=\"node5\">\n<title>140485076743440</title>\n<polygon fill=\"none\" points=\"357.5,-664.5 357.5,-710.5 685.5,-710.5 685.5,-664.5 357.5,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375\" y=\"-683.8\">dot</text>\n<polyline fill=\"none\" points=\"392.5,-664.5 392.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-683.8\">Dot</text>\n<polyline fill=\"none\" points=\"430.5,-664.5 430.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"430.5,-687.5 488.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"488.5,-664.5 488.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587\" y=\"-695.3\">[(None, 14, 64), (None, 4, 64)]</text>\n<polyline fill=\"none\" points=\"488.5,-687.5 685.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587\" y=\"-672.3\">(None, 14, 4)</text>\n</g>\n<!-- 140485076682832&#45;&gt;140485076743440 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140485076682832-&gt;140485076743440</title>\n<path d=\"M403.1831,-747.3799C422.9151,-737.3936 446.1629,-725.6279 466.8048,-715.1811\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"468.4358,-718.2785 475.7777,-710.6399 465.2748,-712.0328 468.4358,-718.2785\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076760208&#45;&gt;140485076743440 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140485076760208-&gt;140485076743440</title>\n<path d=\"M663.8861,-747.4901C639.6533,-737.2803 610.9659,-725.1938 585.7137,-714.5545\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"586.7945,-711.212 576.2201,-710.5547 584.0766,-717.6628 586.7945,-711.212\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076294608 -->\n<g class=\"node\" id=\"node10\">\n<title>140485076294608</title>\n<polygon fill=\"none\" points=\"411.5,-332.5 411.5,-378.5 827.5,-378.5 827.5,-332.5 411.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"453\" y=\"-351.8\">concatenate</text>\n<polyline fill=\"none\" points=\"494.5,-332.5 494.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-351.8\">Concatenate</text>\n<polyline fill=\"none\" points=\"580.5,-332.5 580.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"580.5,-355.5 638.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"609.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"638.5,-332.5 638.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"733\" y=\"-363.3\">[(None, 4, 14), (None, 4, 64)]</text>\n<polyline fill=\"none\" points=\"638.5,-355.5 827.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"733\" y=\"-340.3\">(None, 4, 78)</text>\n</g>\n<!-- 140485076760208&#45;&gt;140485076294608 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140485076760208-&gt;140485076294608</title>\n<path d=\"M717.8193,-747.4076C716.9341,-715.3432 715.5,-655.5187 715.5,-604.5 715.5,-604.5 715.5,-604.5 715.5,-521.5 715.5,-472.2022 710.5358,-456.8618 684.5,-415 677.742,-404.1342 668.4615,-394.0171 659.0281,-385.3194\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"661.2911,-382.6485 651.4752,-378.6612 656.6621,-387.8995 661.2911,-382.6485\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076269200 -->\n<g class=\"node\" id=\"node6\">\n<title>140485076269200</title>\n<polygon fill=\"none\" points=\"370.5,-581.5 370.5,-627.5 672.5,-627.5 672.5,-581.5 370.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"406.5\" y=\"-600.8\">activation</text>\n<polyline fill=\"none\" points=\"442.5,-581.5 442.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481\" y=\"-600.8\">Activation</text>\n<polyline fill=\"none\" points=\"519.5,-581.5 519.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"548.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"519.5,-604.5 577.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"548.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"577.5,-581.5 577.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625\" y=\"-612.3\">(None, 14, 4)</text>\n<polyline fill=\"none\" points=\"577.5,-604.5 672.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625\" y=\"-589.3\">(None, 14, 4)</text>\n</g>\n<!-- 140485076743440&#45;&gt;140485076269200 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140485076743440-&gt;140485076269200</title>\n<path d=\"M521.5,-664.3799C521.5,-656.1745 521.5,-646.7679 521.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"525.0001,-637.784 521.5,-627.784 518.0001,-637.784 525.0001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076269776 -->\n<g class=\"node\" id=\"node8\">\n<title>140485076269776</title>\n<polygon fill=\"none\" points=\"358,-498.5 358,-544.5 685,-544.5 685,-498.5 358,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"377\" y=\"-517.8\">add</text>\n<polyline fill=\"none\" points=\"396,-498.5 396,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417\" y=\"-517.8\">Add</text>\n<polyline fill=\"none\" points=\"438,-498.5 438,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"467\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"438,-521.5 496,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"467\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"496,-498.5 496,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"590.5\" y=\"-529.3\">[(None, 14, 4), (None, 14, 4)]</text>\n<polyline fill=\"none\" points=\"496,-521.5 685,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"590.5\" y=\"-506.3\">(None, 14, 4)</text>\n</g>\n<!-- 140485076269200&#45;&gt;140485076269776 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140485076269200-&gt;140485076269776</title>\n<path d=\"M521.5,-581.3799C521.5,-573.1745 521.5,-563.7679 521.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"525.0001,-554.784 521.5,-544.784 518.0001,-554.784 525.0001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076743568&#45;&gt;140485076269776 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140485076743568-&gt;140485076269776</title>\n<path d=\"M205.6601,-664.3773C244.1775,-641.5617 305.7714,-606.4936 361.5,-581 387.6628,-569.0316 416.9913,-557.5841 443.3224,-547.9836\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"444.6601,-551.2218 452.8763,-544.5325 442.282,-544.6381 444.6601,-551.2218\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076769232 -->\n<g class=\"node\" id=\"node9\">\n<title>140485076769232</title>\n<polygon fill=\"none\" points=\"395.5,-415.5 395.5,-461.5 675.5,-461.5 675.5,-415.5 395.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"427\" y=\"-434.8\">permute</text>\n<polyline fill=\"none\" points=\"458.5,-415.5 458.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490.5\" y=\"-434.8\">Permute</text>\n<polyline fill=\"none\" points=\"522.5,-415.5 522.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"551.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"522.5,-438.5 580.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"551.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"580.5,-415.5 580.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"628\" y=\"-446.3\">(None, 14, 4)</text>\n<polyline fill=\"none\" points=\"580.5,-438.5 675.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"628\" y=\"-423.3\">(None, 4, 14)</text>\n</g>\n<!-- 140485076269776&#45;&gt;140485076769232 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140485076269776-&gt;140485076769232</title>\n<path d=\"M525.3998,-498.3799C526.7838,-490.1745 528.3705,-480.7679 529.8699,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"533.3605,-472.2269 531.5726,-461.784 526.458,-471.0625 533.3605,-472.2269\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076769232&#45;&gt;140485076294608 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140485076769232-&gt;140485076294608</title>\n<path d=\"M558.8987,-415.3799C568.1055,-406.2827 578.8068,-395.7088 588.632,-386.0005\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"591.2822,-388.3023 595.9355,-378.784 586.3621,-383.323 591.2822,-388.3023\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076724496 -->\n<g class=\"node\" id=\"node11\">\n<title>140485076724496</title>\n<polygon fill=\"none\" points=\"494.5,-249.5 494.5,-295.5 744.5,-295.5 744.5,-249.5 494.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515\" y=\"-268.8\">lstm</text>\n<polyline fill=\"none\" points=\"535.5,-249.5 535.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"563.5\" y=\"-268.8\">LSTM</text>\n<polyline fill=\"none\" points=\"591.5,-249.5 591.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"591.5,-272.5 649.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"649.5,-249.5 649.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"697\" y=\"-280.3\">(None, 4, 78)</text>\n<polyline fill=\"none\" points=\"649.5,-272.5 744.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"697\" y=\"-257.3\">(None, 64)</text>\n</g>\n<!-- 140485076294608&#45;&gt;140485076724496 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140485076294608-&gt;140485076724496</title>\n<path d=\"M619.5,-332.3799C619.5,-324.1745 619.5,-314.7679 619.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"623.0001,-305.784 619.5,-295.784 616.0001,-305.784 623.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076774672 -->\n<g class=\"node\" id=\"node12\">\n<title>140485076774672</title>\n<polygon fill=\"none\" points=\"487,-166.5 487,-212.5 752,-212.5 752,-166.5 487,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"518\" y=\"-185.8\">dropout</text>\n<polyline fill=\"none\" points=\"549,-166.5 549,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581.5\" y=\"-185.8\">Dropout</text>\n<polyline fill=\"none\" points=\"614,-166.5 614,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"643\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"614,-189.5 672,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"643\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"672,-166.5 672,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"712\" y=\"-197.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"672,-189.5 752,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"712\" y=\"-174.3\">(None, 64)</text>\n</g>\n<!-- 140485076724496&#45;&gt;140485076774672 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140485076724496-&gt;140485076774672</title>\n<path d=\"M619.5,-249.3799C619.5,-241.1745 619.5,-231.7679 619.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"623.0001,-222.784 619.5,-212.784 616.0001,-222.784 623.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076262864 -->\n<g class=\"node\" id=\"node13\">\n<title>140485076262864</title>\n<polygon fill=\"none\" points=\"500,-83.5 500,-129.5 739,-129.5 739,-83.5 500,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-102.8\">dense</text>\n<polyline fill=\"none\" points=\"549,-83.5 549,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"575\" y=\"-102.8\">Dense</text>\n<polyline fill=\"none\" points=\"601,-83.5 601,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"630\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"601,-106.5 659,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"630\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"659,-83.5 659,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"699\" y=\"-114.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"659,-106.5 739,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"699\" y=\"-91.3\">(None, 22)</text>\n</g>\n<!-- 140485076774672&#45;&gt;140485076262864 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140485076774672-&gt;140485076262864</title>\n<path d=\"M619.5,-166.3799C619.5,-158.1745 619.5,-148.7679 619.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"623.0001,-139.784 619.5,-129.784 616.0001,-139.784 623.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140485076295312 -->\n<g class=\"node\" id=\"node14\">\n<title>140485076295312</title>\n<polygon fill=\"none\" points=\"468.5,-.5 468.5,-46.5 770.5,-46.5 770.5,-.5 468.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"512\" y=\"-19.8\">activation_1</text>\n<polyline fill=\"none\" points=\"555.5,-.5 555.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"594\" y=\"-19.8\">Activation</text>\n<polyline fill=\"none\" points=\"632.5,-.5 632.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"661.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"632.5,-23.5 690.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"661.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"690.5,-.5 690.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"730.5\" y=\"-31.3\">(None, 22)</text>\n<polyline fill=\"none\" points=\"690.5,-23.5 770.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"730.5\" y=\"-8.3\">(None, 22)</text>\n</g>\n<!-- 140485076262864&#45;&gt;140485076295312 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140485076262864-&gt;140485076295312</title>\n<path d=\"M619.5,-83.3799C619.5,-75.1745 619.5,-65.7679 619.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"623.0001,-56.784 619.5,-46.784 616.0001,-56.784 623.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxK-MxYMrKkI"
      },
      "source": [
        "Model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjEgTL9LrKkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407d3505-8bda-4e5f-9df8-9dbae3a30f78"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 14)]         0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, None, 64)     1408        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_4 (Sequential)      (None, None, 64)     1408        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 14, 4)        0           ['sequential_2[0][0]',           \n",
            "                                                                  'sequential_4[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 14, 4)        0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)      (None, None, 4)      88          ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 14, 4)        0           ['activation[0][0]',             \n",
            "                                                                  'sequential_3[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 4, 14)        0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 4, 78)        0           ['permute[0][0]',                \n",
            "                                                                  'sequential_4[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 64)           36608       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 22)           1430        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 22)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 40,942\n",
            "Trainable params: 40,942\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tnbz5YJrKkQ"
      },
      "source": [
        "## 1.5 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_bUUHq-A8Us"
      },
      "source": [
        "In this section we start the training procedure with fitting the data to the designed model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([inputs_train, queries_train], answers_train, batch_size, train_epochs,\n",
        "          validation_data=([inputs_test, queries_test], answers_test))\n",
        "\n",
        "plot_loss(history,\"Loss\")\n",
        "plot_acc(history,\"Accuracy\")\n",
        "\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "c3sOGkotZKmk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35df3660-a81a-4f28-ba4b-7394c54e5e2d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\r  1/313 [..............................] - ETA: 16s - loss: 1.6621 - accuracy: 0.4062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7425 - accuracy: 0.2715 - val_loss: 1.7303 - val_accuracy: 0.2800\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 1.7368 - accuracy: 0.2771 - val_loss: 1.7206 - val_accuracy: 0.3080\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7299 - accuracy: 0.2840 - val_loss: 1.6998 - val_accuracy: 0.3110\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 17s 56ms/step - loss: 1.7183 - accuracy: 0.2946 - val_loss: 1.6886 - val_accuracy: 0.3170\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.7055 - accuracy: 0.3025 - val_loss: 1.6686 - val_accuracy: 0.3360\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 1.6936 - accuracy: 0.3113 - val_loss: 1.6484 - val_accuracy: 0.3340\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 1.6798 - accuracy: 0.3231 - val_loss: 1.6427 - val_accuracy: 0.3520\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 1.6689 - accuracy: 0.3311 - val_loss: 1.6294 - val_accuracy: 0.3460\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 1.6615 - accuracy: 0.3418 - val_loss: 1.6282 - val_accuracy: 0.3560\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 1.6501 - accuracy: 0.3514 - val_loss: 1.6214 - val_accuracy: 0.3670\n",
            "minimum loss is 1.650114893913269 on epoch 10\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum accuracy is 0.3513999879360199 on epoch 10\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXxhXOvcrKkV"
      },
      "source": [
        "## 1.6 Testing and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciBt077dEBLd"
      },
      "source": [
        "Now we need to actually make predictions and check the performance of our trained model with some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4b3f5-arKkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce69c29-b8f4-4f52-b116-0e585ddf8cf1"
      },
      "source": [
        "for i in range(0,10):\n",
        "    current_inp = test_stories[2*i]\n",
        "    current_story, current_query, current_answer = vectorize_stories([current_inp], word_idx, story_maxlen, query_maxlen)\n",
        "    current_prediction = model.predict([current_story, current_query])\n",
        "    current_prediction = idx_word[np.argmax(current_prediction)]\n",
        "    print(' '.join(current_inp[0]), ' '.join(current_inp[1]), '| Prediction:', current_prediction, '| Ground Truth:', current_inp[2])\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is John ? | Prediction: bathroom | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is Sandra ? | Prediction: bathroom | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is Sandra ? | Prediction: bathroom | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Where is Sandra ? | Prediction: hallway | Ground Truth: garden\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Where is Sandra ? | Prediction: hallway | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the office . Mary journeyed to the kitchen . Where is Mary ? | Prediction: kitchen | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the office . Mary journeyed to the kitchen . Where is Daniel ? | Prediction: kitchen | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the office . Mary journeyed to the kitchen . Where is Mary ? | Prediction: kitchen | Ground Truth: bedroom\n",
            "-----------------------------------------------------------------------------------------\n",
            "John moved to the hallway . John journeyed to the kitchen . Where is John ? | Prediction: kitchen | Ground Truth: garden\n",
            "-----------------------------------------------------------------------------------------\n",
            "John moved to the hallway . John journeyed to the kitchen . Where is Daniel ? | Prediction: kitchen | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "DWGbl4PdrKka"
      },
      "source": [
        "## 1.7 Custom Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJUI2SIXEV4x"
      },
      "source": [
        "You can even write your example and test it with your model to see how powerful it is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT83MJ8yrKkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "603970de-087a-4c08-e61d-5197737914ce"
      },
      "source": [
        "print('-------------------------------------------------------------------------------------------')\n",
        "print('Custom User Queries (Make sure there are spaces before each word)')\n",
        "\n",
        "print('-------------------------------------------------------------------------------------------')\n",
        "print('Please input a story')\n",
        "user_story_inp = input().split(' ')\n",
        "print('Please input a query')\n",
        "user_query_inp = input().split(' ')\n",
        "user_story, user_query, user_ans = vectorize_stories([[user_story_inp, user_query_inp, '.']], word_idx, story_maxlen, query_maxlen)\n",
        "user_prediction = model.predict([user_story, user_query])\n",
        "user_prediction = idx_word[np.argmax(user_prediction)]\n",
        "print('Result')\n",
        "print(' '.join(user_story_inp), ' '.join(user_query_inp), '| Prediction:', user_prediction)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------\n",
            "Custom User Queries (Make sure there are spaces before each word)\n",
            "-------------------------------------------------------------------------------------------\n",
            "Please input a story\n",
            "Mary went to the bathroom . Sandra moved to the garden .\n",
            "Please input a query\n",
            "Where is Mary ?\n",
            "Result\n",
            "Mary went to the bathroom . Sandra moved to the garden . Where is Mary ? | Prediction: garden\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4527: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id1unEEQrKkf"
      },
      "source": [
        "# some examples:\n",
        "# Mary went to the bathroom . John moved to the hallway . Mary travelled to the office . # Where is Mary ?\n",
        "# Sandra travelled to the office . John journeyed to the garden ."
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtYRcM2KE4te"
      },
      "source": [
        "As you understood how the model trained, please tell us about the pros and cons of the proposed model. How can we improve it if we want to use it in realistic task ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9NiIbN5F7zb"
      },
      "source": [
        "$\\color{red}{\\text{Write your answer in document}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFKXfqrgQfQm"
      },
      "source": [
        "#  2. Hands on SSL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "0WP9j6u6hADR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7UbcqmKUZ1q"
      },
      "source": [
        "## 2.1 prepare data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "RDOwLbCAjENO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0c6f05-529c-4b23-9ab1-5aecb296b9e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeld_index = np.ones(y_train.shape, np.bool)\n",
        "\n",
        "N = 20\n",
        "for i in range(10):\n",
        "  idx = np.where(y_train == i)[0][:N]\n",
        "  unlabeld_index[idx] = 0"
      ],
      "metadata": {
        "id": "_GMQmFwajGW4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_unlabeld = x_train[np.where(unlabeld_index)[0], ...]\n",
        "\n",
        "x_train = x_train[np.where(~unlabeld_index)[0], ...]\n",
        "y_train = y_train[np.where(~unlabeld_index)[0], ...]"
      ],
      "metadata": {
        "id": "cBwOJ5sJjJOm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examples of categorical crossentropy\n",
        "cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# a labeled data from the second class\n",
        "y_true = [[0, 1, 0, 0]]\n",
        "y_pred = [[0.05, 0.95, 0, 0]]\n",
        "print(cce(y_true, y_pred).numpy())\n",
        "\n",
        "# an ulabeled data\n",
        "y_true = [[0, 0, 0, 0]]\n",
        "y_pred = [[0.05, 0.95, 0, 0]]\n",
        "print(cce(y_true, y_pred).numpy())\n",
        "\n",
        "# another ulabeled data\n",
        "y_true = [[0, 0, 0, 0]]\n",
        "y_pred = [[0.1, 0.4, 0.3, 0.2]]\n",
        "print(cce(y_true, y_pred).numpy())"
      ],
      "metadata": {
        "id": "B4R5nnKejLF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098728bb-2425-4324-fac2-34dfec2d5b13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.051293306\n",
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_categorical_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_categorical_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "qEmQI-5Z98SJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part A\n",
        "\n",
        "train just using labeld data:"
      ],
      "metadata": {
        "id": "NhRKQiQWz8dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model without classifier layers\n",
        "MN2 = MobileNetV2(include_top=False, input_shape=(32, 32, 3), weights=None)\n",
        "# add new classifier layers\n",
        "flatten1 = Flatten()(MN2.layers[-1].output)\n",
        "output1 = Dense(10, activation='softmax')(flatten1)\n",
        "# define new model\n",
        "model1 = Model(inputs=MN2.inputs, outputs=output1)\n",
        "# compile\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "               loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# summarize\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA11EJB_no62",
        "outputId": "3b82265a-4429-4fdb-e0ff-0e4ad1039f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 16, 16, 32)   864         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 16, 16, 32)   128         ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 16, 16, 32)   0           ['bn_Conv1[0][0]']               \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 16, 16, 32)  288         ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 16, 16, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 16, 16, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                                                           ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 16, 16, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 16, 16, 16)  64          ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 16, 16, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 16, 16, 96)  384         ['block_1_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 16, 16, 96)   0           ['block_1_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 17, 17, 96)   0           ['block_1_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 8, 8, 96)    864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 8, 8, 96)    384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 8, 8, 96)     0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 8, 8, 24)     2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 8, 8, 24)    96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 8, 8, 144)    3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 8, 8, 144)   576         ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 8, 8, 144)    0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 8, 8, 144)   1296        ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 8, 8, 144)   576         ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 8, 8, 144)    0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 8, 8, 24)     3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 8, 8, 24)    96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 8, 8, 24)     0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 8, 8, 144)    3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 8, 8, 144)   576         ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 8, 8, 144)    0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 9, 9, 144)    0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 4, 4, 144)   1296        ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 4, 4, 144)   576         ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 4, 4, 144)    0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 4, 4, 32)     4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 4, 4, 32)     0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 4, 4, 32)     0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 5, 5, 192)    0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 2, 2, 192)   1728        ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 2, 2, 192)   768         ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 2, 2, 192)    0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 2, 2, 64)     12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 2, 2, 64)     0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 2, 2, 64)     0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 2, 2, 64)     0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 2, 2, 384)    24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 2, 2, 384)   1536        ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 2, 2, 384)    0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 2, 2, 384)   3456        ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 2, 2, 384)   1536        ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)   0           ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 2, 2, 96)     36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 2, 2, 96)     0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 2, 2, 96)     0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 3, 3, 576)    0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 1, 1, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 1, 1, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 1, 1, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 1, 1, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 1, 1, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 1, 1, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 1, 1, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 1, 1, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 1, 1, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 1280)         0           ['out_relu[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10)           12810       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 2,236,682\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(x_train, y_categorical_train, batch_size=64, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyD4TNv51Il5",
        "outputId": "17449b5a-834c-46a4-f774-aa854231cf3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 16s 47ms/step - loss: 2.6555 - accuracy: 0.1050\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 2.3358 - accuracy: 0.2150\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.2225 - accuracy: 0.2700\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.8701 - accuracy: 0.3400\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.7804 - accuracy: 0.3950\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.9637 - accuracy: 0.3700\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8153 - accuracy: 0.3950\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6190 - accuracy: 0.4400\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.7263 - accuracy: 0.4350\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.6463 - accuracy: 0.4850\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3408 - accuracy: 0.5750\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.3600 - accuracy: 0.5500\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.2711 - accuracy: 0.5850\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3419 - accuracy: 0.5750\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5705 - accuracy: 0.5250\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.3977 - accuracy: 0.5500\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3844 - accuracy: 0.5450\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.2407 - accuracy: 0.6000\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.0579 - accuracy: 0.6800\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.1294 - accuracy: 0.6250\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.1416 - accuracy: 0.5950\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.9464 - accuracy: 0.6600\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.9575 - accuracy: 0.6850\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.8552 - accuracy: 0.7150\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.7438 - accuracy: 0.7700\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.7801 - accuracy: 0.7850\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.5502 - accuracy: 0.8150\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5685 - accuracy: 0.8250\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.6263 - accuracy: 0.8050\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.6489 - accuracy: 0.8250\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.9221 - accuracy: 0.7400\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.7397 - accuracy: 0.7800\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.7459 - accuracy: 0.7500\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5655 - accuracy: 0.8050\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.5526 - accuracy: 0.8550\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5572 - accuracy: 0.8450\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.6588 - accuracy: 0.8000\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.5765 - accuracy: 0.7950\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.7893 - accuracy: 0.7550\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5864 - accuracy: 0.8100\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.6252 - accuracy: 0.8200\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.6826 - accuracy: 0.8050\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.6886 - accuracy: 0.7750\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.6764 - accuracy: 0.7800\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.9733 - accuracy: 0.6850\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.6249 - accuracy: 0.7700\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.8185 - accuracy: 0.7200\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.9204 - accuracy: 0.7300\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.5622 - accuracy: 0.7950\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.6520 - accuracy: 0.8150\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.6068 - accuracy: 0.8300\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.5859 - accuracy: 0.8200\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4851 - accuracy: 0.8500\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3785 - accuracy: 0.8950\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3767 - accuracy: 0.9000\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3226 - accuracy: 0.9150\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.5936 - accuracy: 0.8000\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.5034 - accuracy: 0.8300\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4927 - accuracy: 0.8550\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.6235 - accuracy: 0.8350\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4149 - accuracy: 0.8800\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.5940 - accuracy: 0.8050\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.5930 - accuracy: 0.8350\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.4321 - accuracy: 0.8900\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.5564 - accuracy: 0.8000\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.6360 - accuracy: 0.7800\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.3512 - accuracy: 0.8900\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4021 - accuracy: 0.8450\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4952 - accuracy: 0.8450\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3431 - accuracy: 0.9200\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3948 - accuracy: 0.9200\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3953 - accuracy: 0.8750\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.3708 - accuracy: 0.8700\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.4030 - accuracy: 0.8800\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.2841 - accuracy: 0.9200\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.2981 - accuracy: 0.9250\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.2883 - accuracy: 0.9200\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.2658 - accuracy: 0.9350\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.3304 - accuracy: 0.9400\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.2562 - accuracy: 0.9050\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.3701 - accuracy: 0.8800\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.4448 - accuracy: 0.8650\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3499 - accuracy: 0.9050\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.4321 - accuracy: 0.8450\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3544 - accuracy: 0.9200\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.4201 - accuracy: 0.8900\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3605 - accuracy: 0.9000\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.2286 - accuracy: 0.9500\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.2535 - accuracy: 0.9500\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.2144 - accuracy: 0.9400\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.2560 - accuracy: 0.9250\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.2616 - accuracy: 0.9300\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.2230 - accuracy: 0.9200\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.2530 - accuracy: 0.9300\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.1972 - accuracy: 0.9450\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.2104 - accuracy: 0.9200\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.3329 - accuracy: 0.9100\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3357 - accuracy: 0.9200\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4027 - accuracy: 0.8800\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.6532 - accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8162c0c7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('but accuracy is just', model1.evaluate(x_test, y_categorical_test)[1] * 100,'% on test data!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tySY1SA21QLW",
        "outputId": "02100c25-9861-406f-f998-0cbc05fcc855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 16ms/step - loss: 2.3085 - accuracy: 0.1000\n",
            "but accuracy is just 10.000000149011612 % on test data!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part B\n",
        "\n"
      ],
      "metadata": {
        "id": "IABul8FSEiB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "\n",
        "rotation_options = [None, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
        "l = len(rotation_options)\n",
        "\n",
        "x_rotate = np.zeros(x_unlabeld.shape)\n",
        "y_rotate = np.zeros((x_unlabeld.shape[0],1))\n",
        "for i in range(x_unlabeld.shape[0]):\n",
        "  r = randint(0, l-1)\n",
        "  if r>0:\n",
        "    y_rotate[i,0] = r\n",
        "    x_rotate[i] = cv2.rotate(x_unlabeld[i], rotation_options[r])\n",
        "  else:\n",
        "    y_rotate[i,0] = 0\n",
        "    x_rotate[i] = x_unlabeld[i]\n",
        "\n",
        "y_rotate_categorical = tf.keras.utils.to_categorical(y_rotate)"
      ],
      "metadata": {
        "id": "e8cuvy2BEJur"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MN2 = MobileNetV2(include_top=False, input_shape=(32, 32, 3), weights=None)\n",
        "flatten2 = Flatten()(MN2.layers[-1].output)\n",
        "output2 = Dense(4, activation='softmax')(flatten2)\n",
        "\n",
        "model2 = Model(inputs=MN2.inputs, outputs=output2)\n",
        "\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecnM89EZIgJh",
        "outputId": "9f8ed707-e631-43e8-9d3e-341f5d14dabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 16, 16, 32)   864         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 16, 16, 32)   128         ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 16, 16, 32)   0           ['bn_Conv1[0][0]']               \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 16, 16, 32)  288         ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 16, 16, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 16, 16, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                                                           ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 16, 16, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 16, 16, 16)  64          ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 16, 16, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 16, 16, 96)  384         ['block_1_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 16, 16, 96)   0           ['block_1_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 17, 17, 96)   0           ['block_1_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 8, 8, 96)    864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 8, 8, 96)    384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 8, 8, 96)     0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 8, 8, 24)     2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 8, 8, 24)    96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 8, 8, 144)    3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 8, 8, 144)   576         ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 8, 8, 144)    0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 8, 8, 144)   1296        ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 8, 8, 144)   576         ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 8, 8, 144)    0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 8, 8, 24)     3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 8, 8, 24)    96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 8, 8, 24)     0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 8, 8, 144)    3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 8, 8, 144)   576         ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 8, 8, 144)    0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 9, 9, 144)    0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 4, 4, 144)   1296        ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 4, 4, 144)   576         ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 4, 4, 144)    0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 4, 4, 32)     4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 4, 4, 32)     0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 4, 4, 32)     0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 5, 5, 192)    0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 2, 2, 192)   1728        ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 2, 2, 192)   768         ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 2, 2, 192)    0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 2, 2, 64)     12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 2, 2, 64)     0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 2, 2, 64)     0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 2, 2, 64)     0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 2, 2, 384)    24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 2, 2, 384)   1536        ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 2, 2, 384)    0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 2, 2, 384)   3456        ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 2, 2, 384)   1536        ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)   0           ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 2, 2, 96)     36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 2, 2, 96)     0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 2, 2, 96)     0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 3, 3, 576)    0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 1, 1, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 1, 1, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 1, 1, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 1, 1, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 1, 1, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 1, 1, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 1, 1, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 1, 1, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 1, 1, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 1280)         0           ['out_relu[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            5124        ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,263,108\n",
            "Trainable params: 2,228,996\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(x_rotate, y_rotate_categorical, batch_size=64, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F5uPQXxIrjX",
        "outputId": "6e3ec087-d437-44bd-8d3f-50b3adaf43c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 1.1396 - accuracy: 0.4893\n",
            "Epoch 2/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 1.0222 - accuracy: 0.5719\n",
            "Epoch 3/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.9673 - accuracy: 0.5986\n",
            "Epoch 4/50\n",
            "779/779 [==============================] - 31s 39ms/step - loss: 0.9353 - accuracy: 0.6165\n",
            "Epoch 5/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.9145 - accuracy: 0.6258\n",
            "Epoch 6/50\n",
            "779/779 [==============================] - 31s 39ms/step - loss: 0.9347 - accuracy: 0.6135\n",
            "Epoch 7/50\n",
            "779/779 [==============================] - 31s 39ms/step - loss: 0.8801 - accuracy: 0.6383\n",
            "Epoch 8/50\n",
            "779/779 [==============================] - 31s 39ms/step - loss: 0.8520 - accuracy: 0.6522\n",
            "Epoch 9/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.8271 - accuracy: 0.6644\n",
            "Epoch 10/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.8046 - accuracy: 0.6724\n",
            "Epoch 11/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.7898 - accuracy: 0.6788\n",
            "Epoch 12/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.7656 - accuracy: 0.6923\n",
            "Epoch 13/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.7472 - accuracy: 0.6983\n",
            "Epoch 14/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.7243 - accuracy: 0.7089\n",
            "Epoch 15/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.7067 - accuracy: 0.7186\n",
            "Epoch 16/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.6895 - accuracy: 0.7250\n",
            "Epoch 17/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.6729 - accuracy: 0.7334\n",
            "Epoch 18/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.6537 - accuracy: 0.7411\n",
            "Epoch 19/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.6381 - accuracy: 0.7484\n",
            "Epoch 20/50\n",
            "779/779 [==============================] - 31s 39ms/step - loss: 0.6209 - accuracy: 0.7559\n",
            "Epoch 21/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.6060 - accuracy: 0.7624\n",
            "Epoch 22/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.5986 - accuracy: 0.7657\n",
            "Epoch 23/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.5790 - accuracy: 0.7759\n",
            "Epoch 24/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.5707 - accuracy: 0.7789\n",
            "Epoch 25/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.5540 - accuracy: 0.7861\n",
            "Epoch 26/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.5413 - accuracy: 0.7902\n",
            "Epoch 27/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.5361 - accuracy: 0.7933\n",
            "Epoch 28/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.5138 - accuracy: 0.8024\n",
            "Epoch 29/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.5022 - accuracy: 0.8063\n",
            "Epoch 30/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.4889 - accuracy: 0.8124\n",
            "Epoch 31/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.4838 - accuracy: 0.8148\n",
            "Epoch 32/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.4717 - accuracy: 0.8180\n",
            "Epoch 33/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.4650 - accuracy: 0.8220\n",
            "Epoch 34/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.4500 - accuracy: 0.8273\n",
            "Epoch 35/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.4425 - accuracy: 0.8297\n",
            "Epoch 36/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.4350 - accuracy: 0.8349\n",
            "Epoch 37/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.4213 - accuracy: 0.8378\n",
            "Epoch 38/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.4126 - accuracy: 0.8425\n",
            "Epoch 39/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.4057 - accuracy: 0.8453\n",
            "Epoch 40/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.3929 - accuracy: 0.8506\n",
            "Epoch 41/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.3866 - accuracy: 0.8523\n",
            "Epoch 42/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.3771 - accuracy: 0.8572\n",
            "Epoch 43/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.3735 - accuracy: 0.8574\n",
            "Epoch 44/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.3681 - accuracy: 0.8603\n",
            "Epoch 45/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.3687 - accuracy: 0.8583\n",
            "Epoch 46/50\n",
            "779/779 [==============================] - 32s 41ms/step - loss: 0.3565 - accuracy: 0.8642\n",
            "Epoch 47/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.3461 - accuracy: 0.8692\n",
            "Epoch 48/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.3386 - accuracy: 0.8719\n",
            "Epoch 49/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.3328 - accuracy: 0.8733\n",
            "Epoch 50/50\n",
            "779/779 [==============================] - 31s 40ms/step - loss: 0.3379 - accuracy: 0.8729\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f815f9527d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output3 = Dense(10, activation='softmax')(model2.get_layer('flatten_2').output)\n",
        "model3= Model(inputs=model2.input, outputs=output3)\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqmqvw0JhRCq",
        "outputId": "a05ad072-b087-4c09-f8d6-32158cdfb3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_6\" was not an Input tensor, it was generated by layer \"input_3\".\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\")\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           multiple             0           []                               \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 multiple             864         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  multiple             128         ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              multiple             0           ['bn_Conv1[0][0]']               \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  multiple            288         ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  multiple            128         ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  multiple            0           ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                                                           ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  multiple            512         ['expanded_conv_depthwise_relu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  multiple            64          ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        multiple             1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  multiple            384         ['block_1_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     multiple             0           ['block_1_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    multiple             0           ['block_1_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  multiple            864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  multiple            384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  multiple             0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       multiple             2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  multiple            96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        multiple             3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  multiple            576         ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     multiple             0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  multiple            1296        ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  multiple            576         ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  multiple             0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       multiple             3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  multiple            96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 8, 8, 24)     0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 8, 8, 144)    3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 8, 8, 144)   576         ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 8, 8, 144)    0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 9, 9, 144)    0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 4, 4, 144)   1296        ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 4, 4, 144)   576         ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 4, 4, 144)    0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 4, 4, 32)     4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 4, 4, 32)     0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 4, 4, 32)     0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 5, 5, 192)    0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 2, 2, 192)   1728        ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 2, 2, 192)   768         ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 2, 2, 192)    0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 2, 2, 64)     12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 2, 2, 64)     0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 2, 2, 64)     0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 2, 2, 64)     0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 2, 2, 384)    24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 2, 2, 384)   1536        ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 2, 2, 384)    0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 2, 2, 384)   3456        ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 2, 2, 384)   1536        ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)   0           ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 2, 2, 96)     36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 2, 2, 96)     0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 2, 2, 96)     0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 3, 3, 576)    0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 1, 1, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 1, 1, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 1, 1, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 1, 1, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 1, 1, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 1, 1, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 1, 1, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 1, 1, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 1, 1, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 1280)         0           ['out_relu[0][0]']               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 10)           12810       ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 2,236,682\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "model3.fit(x_train, y_categorical_train, batch_size=64, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRQqHfSth6_8",
        "outputId": "37af645f-616a-491e-8a38-334f9d0c62f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 15s 50ms/step - loss: 2.3225 - accuracy: 0.0900\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 2.3097 - accuracy: 0.0900\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.3064 - accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.2933 - accuracy: 0.1250\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.2861 - accuracy: 0.1450\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2804 - accuracy: 0.1500\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2755 - accuracy: 0.1700\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2666 - accuracy: 0.1500\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.2612 - accuracy: 0.1650\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.2555 - accuracy: 0.1800\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.2546 - accuracy: 0.1950\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.2436 - accuracy: 0.1650\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2397 - accuracy: 0.1750\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.2369 - accuracy: 0.1600\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2295 - accuracy: 0.2000\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2238 - accuracy: 0.1850\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.2138 - accuracy: 0.2050\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 2.2116 - accuracy: 0.2000\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.2023 - accuracy: 0.2200\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.1961 - accuracy: 0.2150\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1903 - accuracy: 0.2050\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.1805 - accuracy: 0.2300\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1721 - accuracy: 0.2500\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 2.1673 - accuracy: 0.2600\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1554 - accuracy: 0.2500\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 2.1508 - accuracy: 0.2800\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1369 - accuracy: 0.2850\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1302 - accuracy: 0.2800\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.1218 - accuracy: 0.3000\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1088 - accuracy: 0.3200\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.1014 - accuracy: 0.3550\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 2.0869 - accuracy: 0.3300\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0810 - accuracy: 0.3600\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.0751 - accuracy: 0.3250\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.0700 - accuracy: 0.3400\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.0474 - accuracy: 0.3800\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.0358 - accuracy: 0.4000\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 2.0243 - accuracy: 0.3950\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.0066 - accuracy: 0.3750\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 2.0082 - accuracy: 0.4100\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.9862 - accuracy: 0.4150\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.9838 - accuracy: 0.4000\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.9788 - accuracy: 0.4450\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.9536 - accuracy: 0.4700\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.9372 - accuracy: 0.4500\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.9389 - accuracy: 0.4550\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.9181 - accuracy: 0.4500\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.8985 - accuracy: 0.4750\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.8843 - accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.8789 - accuracy: 0.4550\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8554 - accuracy: 0.4650\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8373 - accuracy: 0.4900\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.8327 - accuracy: 0.5100\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.8138 - accuracy: 0.4950\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.7953 - accuracy: 0.5350\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.7740 - accuracy: 0.5400\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.7808 - accuracy: 0.5250\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.7544 - accuracy: 0.5650\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.7312 - accuracy: 0.5650\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.7133 - accuracy: 0.6000\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.7031 - accuracy: 0.5900\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.6946 - accuracy: 0.5950\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.6608 - accuracy: 0.6350\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.6595 - accuracy: 0.6150\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.6541 - accuracy: 0.6250\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.6372 - accuracy: 0.5950\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5916 - accuracy: 0.6600\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.5903 - accuracy: 0.6250\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.5762 - accuracy: 0.6650\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.5580 - accuracy: 0.6650\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.5494 - accuracy: 0.6250\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.5284 - accuracy: 0.6450\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.4923 - accuracy: 0.6750\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.5007 - accuracy: 0.6850\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.4766 - accuracy: 0.6750\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.4507 - accuracy: 0.6700\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.4417 - accuracy: 0.6950\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.4122 - accuracy: 0.7050\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.4062 - accuracy: 0.6700\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3960 - accuracy: 0.6600\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.3582 - accuracy: 0.7000\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3317 - accuracy: 0.7100\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.3183 - accuracy: 0.7100\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3153 - accuracy: 0.6900\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.3039 - accuracy: 0.6950\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.2833 - accuracy: 0.7150\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.2487 - accuracy: 0.7100\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.2494 - accuracy: 0.7100\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.2268 - accuracy: 0.7200\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.2163 - accuracy: 0.7200\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.1928 - accuracy: 0.7450\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.1904 - accuracy: 0.7300\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.1806 - accuracy: 0.7400\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.1577 - accuracy: 0.7100\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.1246 - accuracy: 0.7450\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.1332 - accuracy: 0.7350\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.0974 - accuracy: 0.7550\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.0765 - accuracy: 0.7650\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.0744 - accuracy: 0.7450\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.0666 - accuracy: 0.7350\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f815f801ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('result is a little better. the accuracy on test is', \n",
        "      model3.evaluate(x_test, y_categorical_test)[1]*100,\n",
        "      '%'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_WxrfRdjYwS",
        "outputId": "9789e8a7-1f71-4546-962e-58af5a9726ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 6s 18ms/step - loss: 2.7833 - accuracy: 0.1925\n",
            "result is a little better. the accuracy on test is 19.249999523162842 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part C"
      ],
      "metadata": {
        "id": "p6Up_S1ekykr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "all_x_train = np.concatenate((x_train, x_unlabeld))\n",
        "all_y_train = np.concatenate((y_train, np.zeros((x_unlabeld.shape[0], 1))))\n",
        "\n",
        "all_x_train, all_y_train = shuffle(all_x_train, all_y_train)\n",
        "\n",
        "all_y_train_categorical = tf.keras.utils.to_categorical(all_y_train, 10)\n",
        "\n",
        "print(all_x_train.shape)\n",
        "print(all_y_train_categorical.shape)"
      ],
      "metadata": {
        "id": "hoLKl9Sgkd5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea6fd70-f583-4751-8cdb-5ee22209a1da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "\n",
        "rotation_options = [None, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
        "l = len(rotation_options)\n",
        "\n",
        "all_x_train_rotate = np.zeros(all_x_train.shape)\n",
        "all_y_train_rotate = np.zeros((all_x_train.shape[0],1))\n",
        "\n",
        "for i in range(all_x_train.shape[0]):\n",
        "  r = randint(0, l-1)\n",
        "  \n",
        "  if r>0:\n",
        "    all_y_train_rotate[i,0] = r\n",
        "    all_x_train_rotate[i] = cv2.rotate(all_x_train[i], rotation_options[r])\n",
        "\n",
        "  else:\n",
        "    all_y_train_rotate[i,0] = 0\n",
        "    all_x_train_rotate[i] = all_x_train[i]\n",
        "\n",
        "all_y_train_rotate_categorical = tf.keras.utils.to_categorical(all_y_train_rotate, l)\n",
        "print(all_y_train_rotate_categorical.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWbdre9Yny_Q",
        "outputId": "36d7951e-986a-46a2-8de2-5aedf2cce5cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_rotate = np.zeros(x_test.shape)\n",
        "y_test_rotate = np.zeros(y_test.shape)\n",
        "\n",
        "for i in range(x_test.shape[0]):\n",
        "  r = randint(0, l-1)\n",
        "  \n",
        "  if r>0:\n",
        "    y_test_rotate[i,0] = r\n",
        "    x_test_rotate[i] = cv2.rotate(x_test[i], rotation_options[r])\n",
        "\n",
        "  else:\n",
        "    y_test_rotate[i,0] = 0\n",
        "    x_test_rotate[i] = x_test[i]\n",
        "\n",
        "y_test_rotate_categorical = tf.keras.utils.to_categorical(y_test_rotate, l)\n",
        "\n",
        "print(x_test_rotate.shape)\n",
        "print(y_test_rotate_categorical.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkaxw6sNuJVe",
        "outputId": "9ef23e00-acfa-4ed6-b17f-fd62eaa4a458"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3)\n",
            "(10000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MN2 = MobileNetV2(include_top=False, input_shape=(32, 32, 3), weights=None)\n",
        "flatten3 = Flatten()(MN2.layers[-1].output)\n",
        "output3_1 = Dense(4, activation='softmax', name='rotation_out')(flatten3)\n",
        "output3_2 = Dense(10, activation='softmax', name='class_out')(flatten3)\n",
        "\n",
        "model3 = Model(inputs=MN2.inputs, outputs=[output3_1, output3_2])\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0D6Qp3KjZI4",
        "outputId": "c7c7c6f0-0647-4539-c16d-e46917353f78"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 16, 16, 32)   864         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 16, 16, 32)   128         ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 16, 16, 32)   0           ['bn_Conv1[0][0]']               \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 16, 16, 32)  288         ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 16, 16, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 16, 16, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                                                           ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 16, 16, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 16, 16, 16)  64          ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 16, 16, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 16, 16, 96)  384         ['block_1_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 16, 16, 96)   0           ['block_1_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 17, 17, 96)   0           ['block_1_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 8, 8, 96)    864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 8, 8, 96)    384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 8, 8, 96)     0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 8, 8, 24)     2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 8, 8, 24)    96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 8, 8, 144)    3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 8, 8, 144)   576         ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 8, 8, 144)    0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 8, 8, 144)   1296        ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 8, 8, 144)   576         ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 8, 8, 144)    0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 8, 8, 24)     3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 8, 8, 24)    96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 8, 8, 24)     0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 8, 8, 144)    3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 8, 8, 144)   576         ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 8, 8, 144)    0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 9, 9, 144)    0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 4, 4, 144)   1296        ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 4, 4, 144)   576         ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 4, 4, 144)    0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 4, 4, 32)     4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 4, 4, 32)     0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 4, 4, 192)   1728        ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 4, 4, 192)   768         ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 4, 4, 192)    0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 4, 4, 32)     6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 4, 4, 32)    128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 4, 4, 32)     0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 4, 4, 192)    6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 4, 4, 192)   768         ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 4, 4, 192)    0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 5, 5, 192)    0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 2, 2, 192)   1728        ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 2, 2, 192)   768         ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 2, 2, 192)    0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 2, 2, 64)     12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 2, 2, 64)     0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 2, 2, 64)     0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 2, 2, 384)    24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 2, 2, 384)   1536        ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 2, 2, 384)    0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 2, 2, 384)   3456        ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 2, 2, 384)   1536        ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 2, 2, 64)     24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 2, 2, 64)    256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 2, 2, 64)     0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 2, 2, 384)    24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 2, 2, 384)   1536        ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 2, 2, 384)    0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 2, 2, 384)   3456        ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 2, 2, 384)   1536        ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)   0           ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 2, 2, 96)     36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 2, 2, 96)     0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 2, 2, 576)   5184        ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 2, 2, 576)   2304        ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)   0           ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 2, 2, 96)     55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 2, 2, 96)    384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 2, 2, 96)     0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 2, 2, 576)    55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 2, 2, 576)   2304        ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 2, 2, 576)    0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 3, 3, 576)    0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 1, 1, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 1, 1, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 1, 1, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 1, 1, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 1, 1, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 1, 1, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 1, 1, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 1, 1, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 1, 1, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 1, 1, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 1, 1, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 1, 1, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 1, 1, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 1, 1, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 1, 1, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 1, 1, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 1280)         0           ['out_relu[0][0]']               \n",
            "                                                                                                  \n",
            " rotation_out (Dense)           (None, 4)            5124        ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " class_out (Dense)              (None, 10)           12810       ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,275,918\n",
            "Trainable params: 2,241,806\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_with_loss_weights(class_coefficient, rotation_coefficient):\n",
        "  model3 = Model(inputs=MN2.inputs, outputs=[output3_1, output3_2])\n",
        "  model3.compile(\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
        "                loss={\n",
        "                    'class_out': 'categorical_crossentropy', \n",
        "                    'rotation_out': 'categorical_crossentropy'},\n",
        "                loss_weights={\n",
        "                    'class_out': class_coefficient, \n",
        "                    'rotation_out': rotation_coefficient},\n",
        "                metrics={\n",
        "                    'class_out': 'accuracy',\n",
        "                    'rotation_out': 'accuracy'}\n",
        "  )\n",
        "\n",
        "  model3.fit(\n",
        "              all_x_train_rotate,\n",
        "              [all_y_train_rotate_categorical, all_y_train_categorical], \n",
        "              validation_data=(x_test_rotate, [y_test_rotate_categorical, y_categorical_test]),\n",
        "              batch_size=128, \n",
        "              epochs=20\n",
        "  )"
      ],
      "metadata": {
        "id": "41jK3MQZraeZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_with_loss_weights(1, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImEMz_5chO8S",
        "outputId": "dbffa479-7664-4ea4-cc6d-66abc3d0e9e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 31s 64ms/step - loss: 3.4931 - rotation_out_loss: 0.6918 - class_out_loss: 0.0339 - rotation_out_accuracy: 0.7216 - class_out_accuracy: 0.9964 - val_loss: 55.1765 - val_rotation_out_loss: 5.4248 - val_class_out_loss: 28.0525 - val_rotation_out_accuracy: 0.5641 - val_class_out_accuracy: 0.1000\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 3.3660 - rotation_out_loss: 0.6668 - class_out_loss: 0.0320 - rotation_out_accuracy: 0.7347 - class_out_accuracy: 0.9964 - val_loss: 42.4800 - val_rotation_out_loss: 4.3437 - val_class_out_loss: 20.7616 - val_rotation_out_accuracy: 0.5833 - val_class_out_accuracy: 0.1000\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 3.2604 - rotation_out_loss: 0.6457 - class_out_loss: 0.0317 - rotation_out_accuracy: 0.7456 - class_out_accuracy: 0.9964 - val_loss: 34.9468 - val_rotation_out_loss: 3.4336 - val_class_out_loss: 17.7788 - val_rotation_out_accuracy: 0.5929 - val_class_out_accuracy: 0.1000\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 3.1627 - rotation_out_loss: 0.6261 - class_out_loss: 0.0325 - rotation_out_accuracy: 0.7549 - class_out_accuracy: 0.9964 - val_loss: 31.9962 - val_rotation_out_loss: 2.9546 - val_class_out_loss: 17.2230 - val_rotation_out_accuracy: 0.6164 - val_class_out_accuracy: 0.1000\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 3.3627 - rotation_out_loss: 0.6658 - class_out_loss: 0.0335 - rotation_out_accuracy: 0.7357 - class_out_accuracy: 0.9964 - val_loss: 46.4025 - val_rotation_out_loss: 4.7449 - val_class_out_loss: 22.6782 - val_rotation_out_accuracy: 0.5820 - val_class_out_accuracy: 0.1000\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 3.0350 - rotation_out_loss: 0.6007 - class_out_loss: 0.0314 - rotation_out_accuracy: 0.7629 - class_out_accuracy: 0.9964 - val_loss: 35.6949 - val_rotation_out_loss: 3.7606 - val_class_out_loss: 16.8917 - val_rotation_out_accuracy: 0.5848 - val_class_out_accuracy: 0.1000\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 2.9218 - rotation_out_loss: 0.5781 - class_out_loss: 0.0314 - rotation_out_accuracy: 0.7734 - class_out_accuracy: 0.9964 - val_loss: 27.5629 - val_rotation_out_loss: 2.8269 - val_class_out_loss: 13.4282 - val_rotation_out_accuracy: 0.6319 - val_class_out_accuracy: 0.1000\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.8379 - rotation_out_loss: 0.5613 - class_out_loss: 0.0314 - rotation_out_accuracy: 0.7816 - class_out_accuracy: 0.9964 - val_loss: 25.2894 - val_rotation_out_loss: 2.7810 - val_class_out_loss: 11.3842 - val_rotation_out_accuracy: 0.5969 - val_class_out_accuracy: 0.1000\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.7727 - rotation_out_loss: 0.5483 - class_out_loss: 0.0314 - rotation_out_accuracy: 0.7842 - class_out_accuracy: 0.9964 - val_loss: 24.8178 - val_rotation_out_loss: 2.4628 - val_class_out_loss: 12.5037 - val_rotation_out_accuracy: 0.6408 - val_class_out_accuracy: 0.1000\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.6976 - rotation_out_loss: 0.5333 - class_out_loss: 0.0314 - rotation_out_accuracy: 0.7919 - class_out_accuracy: 0.9964 - val_loss: 24.0171 - val_rotation_out_loss: 2.0918 - val_class_out_loss: 13.5580 - val_rotation_out_accuracy: 0.6451 - val_class_out_accuracy: 0.1000\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.6429 - rotation_out_loss: 0.5222 - class_out_loss: 0.0318 - rotation_out_accuracy: 0.7985 - class_out_accuracy: 0.9964 - val_loss: 26.7297 - val_rotation_out_loss: 2.2489 - val_class_out_loss: 15.4854 - val_rotation_out_accuracy: 0.6427 - val_class_out_accuracy: 0.1000\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.5601 - rotation_out_loss: 0.5057 - class_out_loss: 0.0317 - rotation_out_accuracy: 0.8062 - class_out_accuracy: 0.9964 - val_loss: 21.8920 - val_rotation_out_loss: 2.1053 - val_class_out_loss: 11.3657 - val_rotation_out_accuracy: 0.6303 - val_class_out_accuracy: 0.1000\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 2.5039 - rotation_out_loss: 0.4944 - class_out_loss: 0.0321 - rotation_out_accuracy: 0.8086 - class_out_accuracy: 0.9964 - val_loss: 27.1587 - val_rotation_out_loss: 2.5997 - val_class_out_loss: 14.1599 - val_rotation_out_accuracy: 0.6163 - val_class_out_accuracy: 0.1000\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.4379 - rotation_out_loss: 0.4813 - class_out_loss: 0.0312 - rotation_out_accuracy: 0.8152 - class_out_accuracy: 0.9964 - val_loss: 24.6113 - val_rotation_out_loss: 2.5655 - val_class_out_loss: 11.7836 - val_rotation_out_accuracy: 0.6233 - val_class_out_accuracy: 0.1000\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.3658 - rotation_out_loss: 0.4667 - class_out_loss: 0.0321 - rotation_out_accuracy: 0.8206 - class_out_accuracy: 0.9964 - val_loss: 19.9112 - val_rotation_out_loss: 1.9827 - val_class_out_loss: 9.9975 - val_rotation_out_accuracy: 0.6495 - val_class_out_accuracy: 0.0999\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.3115 - rotation_out_loss: 0.4559 - class_out_loss: 0.0320 - rotation_out_accuracy: 0.8248 - class_out_accuracy: 0.9964 - val_loss: 23.7548 - val_rotation_out_loss: 2.3971 - val_class_out_loss: 11.7693 - val_rotation_out_accuracy: 0.6282 - val_class_out_accuracy: 0.1000\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.2217 - rotation_out_loss: 0.4380 - class_out_loss: 0.0320 - rotation_out_accuracy: 0.8333 - class_out_accuracy: 0.9964 - val_loss: 21.5289 - val_rotation_out_loss: 2.0480 - val_class_out_loss: 11.2890 - val_rotation_out_accuracy: 0.6605 - val_class_out_accuracy: 0.1000\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 2.1700 - rotation_out_loss: 0.4276 - class_out_loss: 0.0317 - rotation_out_accuracy: 0.8359 - class_out_accuracy: 0.9964 - val_loss: 27.7916 - val_rotation_out_loss: 2.5489 - val_class_out_loss: 15.0473 - val_rotation_out_accuracy: 0.6270 - val_class_out_accuracy: 0.1000\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.1005 - rotation_out_loss: 0.4136 - class_out_loss: 0.0327 - rotation_out_accuracy: 0.8444 - class_out_accuracy: 0.9964 - val_loss: 24.4459 - val_rotation_out_loss: 2.0249 - val_class_out_loss: 14.3212 - val_rotation_out_accuracy: 0.6615 - val_class_out_accuracy: 0.1000\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 2.0384 - rotation_out_loss: 0.4014 - class_out_loss: 0.0314 - rotation_out_accuracy: 0.8487 - class_out_accuracy: 0.9964 - val_loss: 26.2456 - val_rotation_out_loss: 3.1002 - val_class_out_loss: 10.7449 - val_rotation_out_accuracy: 0.5758 - val_class_out_accuracy: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_with_loss_weights(4, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBZCxo67vdMe",
        "outputId": "74ee4fdc-a142-4bcc-f324-72b32161de2d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 32s 66ms/step - loss: 1.7033 - rotation_out_loss: 1.4693 - class_out_loss: 0.0585 - rotation_out_accuracy: 0.3183 - class_out_accuracy: 0.9939 - val_loss: 19.8074 - val_rotation_out_loss: 1.3877 - val_class_out_loss: 4.6049 - val_rotation_out_accuracy: 0.2513 - val_class_out_accuracy: 0.1000\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.6808 - rotation_out_loss: 1.4965 - class_out_loss: 0.0461 - rotation_out_accuracy: 0.2822 - class_out_accuracy: 0.9964 - val_loss: 28.0089 - val_rotation_out_loss: 1.3936 - val_class_out_loss: 6.6538 - val_rotation_out_accuracy: 0.2502 - val_class_out_accuracy: 0.1000\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 1.6478 - rotation_out_loss: 1.4698 - class_out_loss: 0.0445 - rotation_out_accuracy: 0.2586 - class_out_accuracy: 0.9964 - val_loss: 27.4198 - val_rotation_out_loss: 1.3922 - val_class_out_loss: 6.5069 - val_rotation_out_accuracy: 0.2502 - val_class_out_accuracy: 0.1000\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.5538 - rotation_out_loss: 1.4198 - class_out_loss: 0.0335 - rotation_out_accuracy: 0.2687 - class_out_accuracy: 0.9964 - val_loss: 34.7055 - val_rotation_out_loss: 1.3907 - val_class_out_loss: 8.3287 - val_rotation_out_accuracy: 0.2505 - val_class_out_accuracy: 0.1000\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.5625 - rotation_out_loss: 1.4074 - class_out_loss: 0.0388 - rotation_out_accuracy: 0.2629 - class_out_accuracy: 0.9963 - val_loss: 27.1328 - val_rotation_out_loss: 1.3887 - val_class_out_loss: 6.4360 - val_rotation_out_accuracy: 0.2502 - val_class_out_accuracy: 0.1000\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 1.5124 - rotation_out_loss: 1.3792 - class_out_loss: 0.0333 - rotation_out_accuracy: 0.2848 - class_out_accuracy: 0.9964 - val_loss: 27.6511 - val_rotation_out_loss: 1.4279 - val_class_out_loss: 6.5558 - val_rotation_out_accuracy: 0.2513 - val_class_out_accuracy: 0.1000\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 1.4169 - rotation_out_loss: 1.2820 - class_out_loss: 0.0337 - rotation_out_accuracy: 0.3853 - class_out_accuracy: 0.9964 - val_loss: 31.0299 - val_rotation_out_loss: 1.3602 - val_class_out_loss: 7.4174 - val_rotation_out_accuracy: 0.3535 - val_class_out_accuracy: 0.1000\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.2973 - rotation_out_loss: 1.1645 - class_out_loss: 0.0332 - rotation_out_accuracy: 0.4643 - class_out_accuracy: 0.9964 - val_loss: 32.6977 - val_rotation_out_loss: 1.5678 - val_class_out_loss: 7.7825 - val_rotation_out_accuracy: 0.4050 - val_class_out_accuracy: 0.1000\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 1.2531 - rotation_out_loss: 1.1207 - class_out_loss: 0.0331 - rotation_out_accuracy: 0.4987 - class_out_accuracy: 0.9964 - val_loss: 33.3295 - val_rotation_out_loss: 1.6622 - val_class_out_loss: 7.9168 - val_rotation_out_accuracy: 0.4269 - val_class_out_accuracy: 0.1000\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 1.2156 - rotation_out_loss: 1.0845 - class_out_loss: 0.0328 - rotation_out_accuracy: 0.5208 - class_out_accuracy: 0.9963 - val_loss: 30.2547 - val_rotation_out_loss: 1.5674 - val_class_out_loss: 7.1718 - val_rotation_out_accuracy: 0.4878 - val_class_out_accuracy: 0.1000\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 1.1841 - rotation_out_loss: 1.0546 - class_out_loss: 0.0324 - rotation_out_accuracy: 0.5433 - class_out_accuracy: 0.9964 - val_loss: 38.3265 - val_rotation_out_loss: 1.6973 - val_class_out_loss: 9.1573 - val_rotation_out_accuracy: 0.4816 - val_class_out_accuracy: 0.1000\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.1469 - rotation_out_loss: 1.0193 - class_out_loss: 0.0319 - rotation_out_accuracy: 0.5687 - class_out_accuracy: 0.9964 - val_loss: 36.6903 - val_rotation_out_loss: 2.0080 - val_class_out_loss: 8.6706 - val_rotation_out_accuracy: 0.5358 - val_class_out_accuracy: 0.1000\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.1181 - rotation_out_loss: 0.9892 - class_out_loss: 0.0322 - rotation_out_accuracy: 0.5888 - class_out_accuracy: 0.9964 - val_loss: 38.7685 - val_rotation_out_loss: 2.3428 - val_class_out_loss: 9.1064 - val_rotation_out_accuracy: 0.4986 - val_class_out_accuracy: 0.1000\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.0944 - rotation_out_loss: 0.9656 - class_out_loss: 0.0322 - rotation_out_accuracy: 0.6005 - class_out_accuracy: 0.9964 - val_loss: 38.8946 - val_rotation_out_loss: 2.5587 - val_class_out_loss: 9.0840 - val_rotation_out_accuracy: 0.5059 - val_class_out_accuracy: 0.1000\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 1.0721 - rotation_out_loss: 0.9442 - class_out_loss: 0.0320 - rotation_out_accuracy: 0.6103 - class_out_accuracy: 0.9964 - val_loss: 43.5239 - val_rotation_out_loss: 2.9941 - val_class_out_loss: 10.1324 - val_rotation_out_accuracy: 0.5312 - val_class_out_accuracy: 0.1000\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.0845 - rotation_out_loss: 0.9557 - class_out_loss: 0.0322 - rotation_out_accuracy: 0.6033 - class_out_accuracy: 0.9964 - val_loss: 55.8122 - val_rotation_out_loss: 4.7401 - val_class_out_loss: 12.7680 - val_rotation_out_accuracy: 0.4664 - val_class_out_accuracy: 0.1000\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.0449 - rotation_out_loss: 0.9153 - class_out_loss: 0.0324 - rotation_out_accuracy: 0.6245 - class_out_accuracy: 0.9964 - val_loss: 42.5208 - val_rotation_out_loss: 3.2226 - val_class_out_loss: 9.8246 - val_rotation_out_accuracy: 0.5368 - val_class_out_accuracy: 0.1000\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 1.0228 - rotation_out_loss: 0.8957 - class_out_loss: 0.0318 - rotation_out_accuracy: 0.6330 - class_out_accuracy: 0.9964 - val_loss: 43.4334 - val_rotation_out_loss: 3.0589 - val_class_out_loss: 10.0936 - val_rotation_out_accuracy: 0.5364 - val_class_out_accuracy: 0.1000\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 1.0118 - rotation_out_loss: 0.8851 - class_out_loss: 0.0317 - rotation_out_accuracy: 0.6370 - class_out_accuracy: 0.9964 - val_loss: 42.0423 - val_rotation_out_loss: 3.2382 - val_class_out_loss: 9.7010 - val_rotation_out_accuracy: 0.5318 - val_class_out_accuracy: 0.1000\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.0403 - rotation_out_loss: 0.9139 - class_out_loss: 0.0316 - rotation_out_accuracy: 0.6266 - class_out_accuracy: 0.9964 - val_loss: 52.8178 - val_rotation_out_loss: 4.2122 - val_class_out_loss: 12.1514 - val_rotation_out_accuracy: 0.3913 - val_class_out_accuracy: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_with_loss_weights(1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMrUvkP3mIxr",
        "outputId": "90258ad6-c253-427c-a360-ec40113ebe55"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "391/391 [==============================] - 31s 64ms/step - loss: 1.6153 - rotation_out_loss: 1.5512 - class_out_loss: 0.0641 - rotation_out_accuracy: 0.2850 - class_out_accuracy: 0.9947 - val_loss: 5.9792 - val_rotation_out_loss: 1.4043 - val_class_out_loss: 4.5749 - val_rotation_out_accuracy: 0.2503 - val_class_out_accuracy: 0.1000\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 1.3666 - rotation_out_loss: 1.3302 - class_out_loss: 0.0364 - rotation_out_accuracy: 0.3552 - class_out_accuracy: 0.9964 - val_loss: 7.2027 - val_rotation_out_loss: 1.4014 - val_class_out_loss: 5.8012 - val_rotation_out_accuracy: 0.2505 - val_class_out_accuracy: 0.1000\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.1660 - rotation_out_loss: 1.1299 - class_out_loss: 0.0361 - rotation_out_accuracy: 0.4969 - class_out_accuracy: 0.9963 - val_loss: 8.4604 - val_rotation_out_loss: 1.3975 - val_class_out_loss: 7.0629 - val_rotation_out_accuracy: 0.2480 - val_class_out_accuracy: 0.1000\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.0879 - rotation_out_loss: 1.0536 - class_out_loss: 0.0343 - rotation_out_accuracy: 0.5502 - class_out_accuracy: 0.9964 - val_loss: 8.9821 - val_rotation_out_loss: 1.4057 - val_class_out_loss: 7.5763 - val_rotation_out_accuracy: 0.2549 - val_class_out_accuracy: 0.1000\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.0333 - rotation_out_loss: 1.0002 - class_out_loss: 0.0331 - rotation_out_accuracy: 0.5794 - class_out_accuracy: 0.9964 - val_loss: 9.1979 - val_rotation_out_loss: 1.5023 - val_class_out_loss: 7.6957 - val_rotation_out_accuracy: 0.3038 - val_class_out_accuracy: 0.1000\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 1.0066 - rotation_out_loss: 0.9732 - class_out_loss: 0.0334 - rotation_out_accuracy: 0.5969 - class_out_accuracy: 0.9964 - val_loss: 10.0021 - val_rotation_out_loss: 1.4671 - val_class_out_loss: 8.5350 - val_rotation_out_accuracy: 0.3446 - val_class_out_accuracy: 0.1000\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.9778 - rotation_out_loss: 0.9452 - class_out_loss: 0.0326 - rotation_out_accuracy: 0.6085 - class_out_accuracy: 0.9964 - val_loss: 8.5970 - val_rotation_out_loss: 1.1943 - val_class_out_loss: 7.4027 - val_rotation_out_accuracy: 0.4755 - val_class_out_accuracy: 0.1000\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.9540 - rotation_out_loss: 0.9212 - class_out_loss: 0.0327 - rotation_out_accuracy: 0.6210 - class_out_accuracy: 0.9964 - val_loss: 8.9247 - val_rotation_out_loss: 1.0447 - val_class_out_loss: 7.8800 - val_rotation_out_accuracy: 0.5645 - val_class_out_accuracy: 0.1000\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.9281 - rotation_out_loss: 0.8955 - class_out_loss: 0.0325 - rotation_out_accuracy: 0.6301 - class_out_accuracy: 0.9964 - val_loss: 9.7632 - val_rotation_out_loss: 1.4080 - val_class_out_loss: 8.3553 - val_rotation_out_accuracy: 0.5744 - val_class_out_accuracy: 0.1000\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.9503 - rotation_out_loss: 0.9175 - class_out_loss: 0.0327 - rotation_out_accuracy: 0.6228 - class_out_accuracy: 0.9964 - val_loss: 11.6691 - val_rotation_out_loss: 1.9778 - val_class_out_loss: 9.6914 - val_rotation_out_accuracy: 0.5653 - val_class_out_accuracy: 0.1000\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.9061 - rotation_out_loss: 0.8739 - class_out_loss: 0.0323 - rotation_out_accuracy: 0.6452 - class_out_accuracy: 0.9964 - val_loss: 15.3703 - val_rotation_out_loss: 2.8113 - val_class_out_loss: 12.5590 - val_rotation_out_accuracy: 0.5308 - val_class_out_accuracy: 0.1000\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.8781 - rotation_out_loss: 0.8461 - class_out_loss: 0.0319 - rotation_out_accuracy: 0.6543 - class_out_accuracy: 0.9964 - val_loss: 18.0757 - val_rotation_out_loss: 4.4198 - val_class_out_loss: 13.6559 - val_rotation_out_accuracy: 0.5100 - val_class_out_accuracy: 0.1000\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.8557 - rotation_out_loss: 0.8236 - class_out_loss: 0.0321 - rotation_out_accuracy: 0.6650 - class_out_accuracy: 0.9964 - val_loss: 15.0199 - val_rotation_out_loss: 3.4534 - val_class_out_loss: 11.5665 - val_rotation_out_accuracy: 0.5475 - val_class_out_accuracy: 0.1000\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8406 - rotation_out_loss: 0.8087 - class_out_loss: 0.0320 - rotation_out_accuracy: 0.6717 - class_out_accuracy: 0.9964 - val_loss: 14.9141 - val_rotation_out_loss: 3.4494 - val_class_out_loss: 11.4648 - val_rotation_out_accuracy: 0.5685 - val_class_out_accuracy: 0.1000\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8230 - rotation_out_loss: 0.7913 - class_out_loss: 0.0317 - rotation_out_accuracy: 0.6803 - class_out_accuracy: 0.9964 - val_loss: 15.1207 - val_rotation_out_loss: 3.5073 - val_class_out_loss: 11.6134 - val_rotation_out_accuracy: 0.5884 - val_class_out_accuracy: 0.1000\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8028 - rotation_out_loss: 0.7712 - class_out_loss: 0.0317 - rotation_out_accuracy: 0.6879 - class_out_accuracy: 0.9964 - val_loss: 14.1760 - val_rotation_out_loss: 3.9012 - val_class_out_loss: 10.2747 - val_rotation_out_accuracy: 0.5510 - val_class_out_accuracy: 0.1000\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.7885 - rotation_out_loss: 0.7572 - class_out_loss: 0.0314 - rotation_out_accuracy: 0.6930 - class_out_accuracy: 0.9964 - val_loss: 15.9007 - val_rotation_out_loss: 3.7701 - val_class_out_loss: 12.1306 - val_rotation_out_accuracy: 0.5661 - val_class_out_accuracy: 0.1000\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.7682 - rotation_out_loss: 0.7370 - class_out_loss: 0.0312 - rotation_out_accuracy: 0.7009 - class_out_accuracy: 0.9964 - val_loss: 14.4397 - val_rotation_out_loss: 3.2333 - val_class_out_loss: 11.2063 - val_rotation_out_accuracy: 0.5798 - val_class_out_accuracy: 0.1000\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.7613 - rotation_out_loss: 0.7298 - class_out_loss: 0.0315 - rotation_out_accuracy: 0.7075 - class_out_accuracy: 0.9964 - val_loss: 15.1596 - val_rotation_out_loss: 3.3943 - val_class_out_loss: 11.7653 - val_rotation_out_accuracy: 0.5738 - val_class_out_accuracy: 0.1000\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 24s 63ms/step - loss: 0.7415 - rotation_out_loss: 0.7100 - class_out_loss: 0.0315 - rotation_out_accuracy: 0.7157 - class_out_accuracy: 0.9964 - val_loss: 26.4898 - val_rotation_out_loss: 6.0250 - val_class_out_loss: 20.4647 - val_rotation_out_accuracy: 0.5030 - val_class_out_accuracy: 0.1000\n"
          ]
        }
      ]
    }
  ]
}